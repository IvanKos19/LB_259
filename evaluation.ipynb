{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba5588f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order_ID Customer_ID Customer_Type             Product     Category  \\\n",
      "0     ORD1     CUS1496           B2B          Vio Wasser        Water   \n",
      "1     ORD1     CUS1496           B2B               Evian        Water   \n",
      "2     ORD1     CUS1496           B2B              Sprite  Soft Drinks   \n",
      "3     ORD1     CUS1496           B2B  Rauch Multivitamin       Juices   \n",
      "4     ORD1     CUS1496           B2B        Gerolsteiner        Water   \n",
      "\n",
      "   Unit_Price  Quantity  Discount  Total_Price             Region  Order_Date  \n",
      "0        1.66        53      0.10        79.18  Baden-Württemberg  23.08.2023  \n",
      "1        1.56        90      0.10       126.36  Baden-Württemberg  23.08.2023  \n",
      "2        1.17        73      0.05        81.14  Baden-Württemberg  23.08.2023  \n",
      "3        3.22        59      0.10       170.98  Baden-Württemberg  23.08.2023  \n",
      "4        0.87        35      0.10        27.40  Baden-Württemberg  23.08.2023  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   Order_ID       1048575 non-null  object \n",
      " 1   Customer_ID    1048575 non-null  object \n",
      " 2   Customer_Type  1048575 non-null  object \n",
      " 3   Product        1048575 non-null  object \n",
      " 4   Category       1048575 non-null  object \n",
      " 5   Unit_Price     1048575 non-null  float64\n",
      " 6   Quantity       1048575 non-null  int64  \n",
      " 7   Discount       1048575 non-null  float64\n",
      " 8   Total_Price    1048575 non-null  float64\n",
      " 9   Region         1048575 non-null  object \n",
      " 10  Order_Date     1048575 non-null  object \n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 88.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\kosiv\\OneDrive\\Desktop\\BBB\\M259\\archive\\synthetic_beverage_sales_data.csv\", sep=';')\n",
    "print(data.head())\n",
    "data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e297d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Feature  Importance\n",
      "3           Total_Price    0.430072\n",
      "0            Unit_Price    0.369684\n",
      "1              Quantity    0.188593\n",
      "2              Discount    0.007574\n",
      "6  Category_Soft Drinks    0.001548\n",
      "5       Category_Juices    0.001330\n",
      "7        Category_Water    0.001004\n",
      "4     Customer_Type_B2C    0.000193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Wähle Features (X) und Zielvariable (y)\n",
    "X = data[['Customer_Type', 'Category', 'Unit_Price', 'Quantity', 'Discount', 'Total_Price']]\n",
    "y = data['Region']\n",
    "\n",
    "# One-hot Encoding für kategorische Felder\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Datensatz aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Wichtige Features bestimmen\n",
    "importances = model.feature_importances_\n",
    "features = X_encoded.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ac133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Optimierte Modellgenauigkeit: 22.55%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Parameter-Raum definieren\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random Forest vorbereiten\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Suche starten\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Bestes Modell\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Neue Vorhersagen\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Optimierte Modellgenauigkeit: {accuracy_best:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296db285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Parameterraum\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Randomized Search Setup\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Modelltraining\n",
    "random_search.fit(X_train, y_train)\n",
    "best_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f7ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Vorhersagen mit dem getunten Modell\n",
    "y_pred_best = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f2d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2593 3634 3021 1771 2192]\n",
      " [1920 4620 3261 1944 2318]\n",
      " [1830 3920 3542 1901 2411]\n",
      " [1873 3931 3155 2133 2484]\n",
      " [1770 3838 3451 1842 2444]]\n",
      "\n",
      "Recall-Werte (Sensitivität) pro Klasse:\n",
      "Bremen: Recall = 0.20\n",
      "Hamburg: Recall = 0.33\n",
      "Niedersachsen: Recall = 0.26\n",
      "Rheinland-Pfalz: Recall = 0.16\n",
      "Sachsen: Recall = 0.18\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_best, labels=best_model.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nRecall-Werte (Sensitivität) pro Klasse:\")\n",
    "report = classification_report(y_test, y_pred_best, output_dict=True)\n",
    "for label, metrics in report.items():\n",
    "    if label not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        print(f\"{label}: Recall = {metrics['recall']:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73550d7c",
   "metadata": {},
   "source": [
    "## Teil 4.4 – Zusammenfassung & Hypothesen\n",
    "\n",
    "Das Modell erreicht nach Hyperparameter-Tuning auf die fünf häufigsten Regionen eine Genauigkeit von **22.55 %**. Dies stellt eine deutliche Verbesserung gegenüber der ursprünglichen Genauigkeit von 7.18 % dar.\n",
    "\n",
    "**Recall-Werte (Sensitivität):**\n",
    "- Bremen: 20 %\n",
    "- Hamburg: 33 %\n",
    "- Niedersachsen: 26 %\n",
    "- Rheinland-Pfalz: 16 %\n",
    "- Sachsen: 18 %\n",
    "\n",
    "**Interpretation:**\n",
    "Die Region **Hamburg** wird vom Modell am besten erkannt. Dies kann an klareren Kaufmustern oder einer größeren Repräsentation im Datensatz liegen. Andere Regionen wie **Rheinland-Pfalz** oder **Sachsen** zeigen niedrigere Recall-Werte, was auf Überschneidungen im Kaufverhalten mit anderen Regionen hindeutet.\n",
    "\n",
    "**Hypothesen zur Modellleistung:**\n",
    "- Preis- und Mengendaten allein reichen nur begrenzt zur Regionenvorhersage aus.\n",
    "- Die besten Prädiktoren waren `Total_Price`, `Unit_Price` und `Quantity`.\n",
    "- Weitere Verbesserungen wären mit geografischen, zeitlichen oder benutzerspezifischen Merkmalen möglich.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
